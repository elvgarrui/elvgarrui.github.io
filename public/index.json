[{"content":"This post is a really basic introduction on how to start developing at Neutron. The goal is to provide an idea of what the workflow is and which tools you need when fixing a bug in the project. Hopefully, I can help anyone interested in making a first contribution to the project! Please use this together with Neutron\u0026rsquo;s official Contributor\u0026rsquo;s Guide.\nThis blog post assumes you are familiar with git and python coding.\nIntro to Neutron Openstack is cloud software that has multiple use cases and is widely used all over the world. It is a set of multiple components, and not every component is needed for every deployment (See this page for some examples).\nThere are some components that must be present regardless of the use case. Neutron, also known as the Openstack Networking Service, is one of them. It manages all of the virtual network infrastructure, both in the control and the data plane of Openstack. The codebase is big, so it can get a bit complex at first, but there is a community of contributors that are very active on IRC, where you can ask any questions. Note that most developers are usually busy people and getting answers might not be something immediate, but everyone will do their best to help new devs to understand Neutron better. You can also go to the weekly neutron team meeting on IRC.\nCheck the Contributing section of Neutron documentation for up to date information!\nNeutron\u0026rsquo;s Launchpad is the tool to track bugs from the project. If you have already spotted a problem in the code, don\u0026rsquo;t hesitate to report it and fix it, but if you don\u0026rsquo;t know where to start and it\u0026rsquo;s your first time in the project, search for bugs tagged as \u0026ldquo;low-hanging-fruit\u0026rdquo;.\nIf you need some help with network basics, Neutron Documentation also has an informative section on networking concepts that are widely used within the project.\nDeploying an environment using Devstack Once you have chosen your first bug, it\u0026rsquo;s time to replicate it. Because of the complexity of most Openstack deployments, we usually start reproducing and checking the bugs using Devstack. Devstack is a development version of the Openstack environment, and it should not be used as a production environment. It is based on the latest versions of every component, and it\u0026rsquo;s also used as the base for functional tests. It is very important to run this environment in a VM since it will make important changes in the system during the installation.\nThe configuration file that you will need to tune, depending on the needs of your testing, is local.conf. I use the configuration file that comes with neutron for OVN, since that\u0026rsquo;s the kind of environment that I usually want to replicate, but this part is really customizable depending on what you need. If the bug you want to debug is related to OVN I recommend compiling OVN from source instead of downloading it as a package. That way you will get the latest master version and not the last stable packaged one. You can check the local.conf I used while writing this blog post in case it helps.\nThis guide for deploying Devstack + OVN from the documentation is the one that has guided me during the process of installation of Devstack.\nOnce you finish running ./stack.sh and have your VM with Devstack installed, you are ready to start using the env.\nSome tips regarding this environment:\nDon\u0026rsquo;t shut off your VM. There is not a clean way to restack Devstack after a reboot. Since the environment is only for testing and developing, there is also no need to make it persistent, but it\u0026rsquo;s something to bear in mind before powering off your host.\nTake a snapshot a after a clean deploy. Since you are going to manipulate this system heavily you might get to inconsistent states. It is also not recommended to stay in the same environment for months. One of the points of Devstack is to have the latest updates from the projects, but keeping the same environment for one bug might save you time and a lot of headaches on your earlier contributions.\nWhenever you make a change in the Neutron project, restart the networking services. {% highlight bash %} systemctl restart devstack@q-svc {% endhighlight %}\nUse a VM of the distribution you find more suitable for yourself. It could be Fedora, Ubuntu, CentOS, or OpenSUSE. I\u0026rsquo;m currently using Ubuntu 20.04, because that\u0026rsquo;s the one we use on the testing gates, but don\u0026rsquo;t feel obligated to do the same.\nIf stack.sh finishes successfully, you should be able to see this:\nThis is your host IP address: 172.16.189.6 This is your host IPv6 address: ::1 Horizon is now available at http://172.16.189.6/dashboard Keystone is serving at http://172.16.189.6/identity/ The default users are: admin and demo The password: password 2021-03-09 11:02:12.001 | stack.sh completed in 1998 seconds. That means your deployment was successfully deployed!\nAdding some workload to the deployment By workload, I\u0026rsquo;m referring to networks, routers, VM instances, security groups\u0026hellip; Any actual component that you need to replicate the bug you are working to solve. There are some cases (i.e. working with Network Agents) where no additional objects need to be spawned, but it is always good to know how to spawn some basic resources.\nAlthough there is a Dashboard available (Horizon), not every Neutron feature is supported there. It is important to learn how to use the Openstack CLI from the terminal so as to get a real understanding of how it works.\nFirst of all, check that you have images and flavors already there. You will need them to spawn VM instances:\n$ openstack flavor list $ openstack image list If you need to add an image, bear in mind that it needs to be a cloud version. For developing purposes we will use Cirros. I usually download it with:\n$ curl -k -L [image_url] \u0026gt; [image_name.img] $ openstack image create [image_name.img] cirros The flavor I create for cirros is 1 GB of disk, and 128 of RAM.\n$ flavor create m1.small --disk 1 --vcpus 1 --ram 64 After that, I create a basic network topology:\n$ openstack network create net1 $ openstack subnet create --subnet-range 192.168.100.0/24 --network net1 subnet1 $ openstack router create r1 $ openstack router add subnet r1 subnet1 $ openstack router set --external-gateway public r1 #public is the external network $ openstack security group create secgroup1 $ openstack security group rule create --protocol tcp --dst-port 22 secgroup1 $ openstack security group rule create --protocol icmp secgroup1 $ openstack server create --nic net-id=net1 --flavor m1.small --image cirros \\ --security-group secgroup1 server1 The result will be a topology like this: The security group associated to the VM allows TCP traffic on port 22 and also icmp traffic on the server. By default, the servers are completely isolated from traffic. To access the VM you will need to associate a floating ip to the VM.\nFirst, we create the floating IP\n$ openstack floating ip create nova We look for the floating IP ID\n$ openstack floating ip list And for the ID of the port associated to the server\n$ nova interface-list server1 Finally, we associate the port to the floating IP\n$ openstack floating ip set --port 5f798f30-d78b-4da2-95a4-7785aeeb6016 \\ c617ec29-3b64-45b3-b32b-4b74b6a1804d After this, you should be able to ping and access the VM from your undercloud using its floating IP.\nSome basic debugging tools There is not a single way to debug Neutron. It depends on your preferences. Depending on the complexity, you might want to check PDB or remote PDB, a wrapper that uses a tcp socket to comunicate with the external world.\nSometimes, adding logs might be enough for debugging purposes. If you want to check the logs in Devstack, use:\n$ journalctl -u devstack@q-svc.service If you are running the unit tests and want to debug those, you should enter the virtual environment created and execute stestr from there, otherwise you won\u0026rsquo;t be able to correctly work with the debugging tool:\nsource .tox/py38/bin/activate stestr run -n \u0026lt;test path\u0026gt; I won\u0026rsquo;t go into the details regarding the code because the codebase is huge and therefore the explanation would change depending on the fix you need to do. Nevertheless, there are some tools that will make your life easier when confronting the code at first:\nTo search keywords within the Neutron Code I use ripgrep or grep. To search across the Openstack environment you can use the Hound code searcher. It will help in case you need to see how an object is used by different components, or see related files from other related repositories like neutron-tempest-plugins, which contains Neutron scenario tests. Running the tests Once you think you have the solution to the problem, you must ensure the code is correct before uploading it. If possible, also create at least a unit test that ensures your change will stay functional over time. Before writing your unit tests, read this post by Otherwiseguy on how NOT to write Python unit tests. It will help you creating better code on the long run.\nThe official documentation will provide up-to-date information on how to check your code. Tox is the main tool that provides a compilation of syntax, unit and functional tests. To ensure the syntax of your code is correct, you must run tox -e pep8. Unit tests must also pass successfully: tox -e py38 (the number next to py indicates the python version you want to use for testing). Finally, it is also nice to ensure functional tests are working as expected. In the Docs you will find functional and dsvm-functional. The latter is the one we need to check tox -e dsvm-functional. As advised, please use Devstack within a VM to execute those.\nIf you want to check only a certain group of tests, Tox supports filtering, so you can do something like this for unit and functional tests:\ntox -e py38 -- neutron.tests.unit.services.ovn_l3 Once you upload your changes, your code will also go through the Zuul gates, and further testing will be performed.\nUploading your change! All projects in Openstack are managed using Gerrit, an extension to git that works a bit differently than what you might be used to in GitHub/GitLab. See more on how to set up your Gerrit account.\nInstead of pull request, commits are reviewed individually (although they can be chained). Use git review to upload your changes. You do not need to have a branch dedicated, but it is a good practice to make the changes in a branch named after the bug you are solving. It is important that your commit message is clear and that the changes that are uploaded stick strictly to your intended changes.\nYour commit will be then reviewed by the community, where each person can decide to +1 or -1 your commit. If your commit is -1\u0026rsquo;d, you will get information on why that person decided your commit was not yet ready to be merged. Core reviewers can give you +2, and when at least 2 core reviewers give your commit +2, your code will be ready to be merged!\n","permalink":"http://localhost:1313/posts/2022-08-24-101neutron/","title":"Fixing your first bug in Neutron: 101"},{"content":"Linux System Roles are a collection of roles and modules that assist Linux administrators in the configuration of GNU/Linux subsystems through Ansible. There are roles for managing different parts of the systems such as selinux, storage and networking.\nImproving the Network Linux System Role My main objective was to improve the Network Linux System Role. Although my proposal covered the many different tasks that were suggested for the project, my mentors and I decided to better focus on improving the integration testing of the project. Therefore, most of my contributions were related to this matter. Adding Pytest as an integration testing tool is the most remarkable addition to the project. Below you can see the detailed list of my contributions:\nMerged PRs Started before 1st May, 2020:\nPR207 - Separate debug and info logs from warnings: Fixes Issue 29. After 1st May, 2020:\nPR226 - Update contributing.md with steps to contributing.\nPR223 - Change ethtool features to use underscores. Refers to Issue 206. The role now accepts properties written with underscores or dashes, and fails if both options are mixed.\nPR237 - Fail if state and persistent_state are incompatible: Fixes Issue 205.\nPR251 - Fix error message format.\nPR260 - Add Pytest integration tests: This PR contains two different commits. The first one creates the script for testing and the mocking of the Ansible runtime. The second one consists of playbooks that allow Pytest to run in the project-internal test-harness. The test-harness allows the execution of these tests in different Linux distributions such as CentOS, Fedora and RHEL.\nTodo There are some tasks that still need to be finished. The most important is to add Python 2 support to the Pytest integration testing, which is needed to be able to test older releases of THEL or CentOS. After that, I also want to finish Issue 206 by adding warnings when a deprecated property is used.\nüå§Ô∏è Summer is ending\u0026hellip; üå§Ô∏è It has been an intense but rewarding summer, and I\u0026rsquo;ve learnt a lot. I\u0026rsquo;ve been able to work directly with awesome professionals. I\u0026rsquo;m willing to continue contributing to Linux System Roles and to improve my skills as a software engineer!!\nThanks to Fedora and all the mentors. Thanks to Till for being so understanding and patient with me. I really appreciate all the time you have dedicated to my mentoring.\n","permalink":"http://localhost:1313/posts/2020-08-27-gsoc-summary/","title":"My journey at Linux System Roles with GSoC"},{"content":"Summary In this post I will explain a bit about my most relevant work during July at GSoC: Running an Ansible module directly from Python and how and why it can be useful to mock Python modules sometimes.\nIntroduction My main task in the GSoC project is to add Pytest to the Network Role at Linux System Roles. This will lead to a better coverage of tests, since all the utilities of pytest will be available for testing the module, instead of being limited to the execution from a playbook. This does not mean that playbooks will not be used anymore (it is still useful to see how Ansible reacts to the different tasks!), but that a more in-depth testing will be possible. It will be possible to test classes and functions individually and to use pytest features like fixture or parametrize.\nIn order to achieve this, I had to mock some objects. This is necessary because the module is meant to be executed only from Ansible, and thus some dependencies go missing. Furthermore, the available system paths also change depending on where you execute the module from, so it was also necessary to mock this attribute.\nWhy is it really necessary to make this mocking? We need to access the different functions and classes in library/network_connections.py in order to test the module. But if we just write import library.network_connections.py a module not found error will rise for ansible.module_utils.network_lsr. This happens because in the git repository, argument_validator.py can be found inside network/module_utils/network_lsr/. On the target system, which is where we will execute the module if we run Ansible, it is located in ansible/module_utils/network_lsr/ instead. Therefore, given that we do not want to change the imports of the module, the best option is to make the system \u0026ldquo;believe\u0026rdquo; that our module_utils/ is inside of an ansible module by mocking it.\nSumming it up: When we execute the module through Ansible, Ansible exports the necessary Python files to the target system (which would be: folders modules/ and module_utils/). Because we are executing the module without Ansible and in our \u0026ldquo;host\u0026rdquo; system, these ansible modules need to be mocked.\nTo exactly see what Ansible deploys on your target system, you can follow these steps:\nExecute any playbook with the flag \u0026ldquo;ANSIBLE_KEEP_REMOTE_FILES=1\u0026rdquo; to avoid the files being erased after their use. Inside the target system, search for the file which contains the compressed Ansible folder. I used find -name *network* to find the file (AnsiballZ_network_connections.py) Execute /usr/libexec/platform-python path/to/AnsiballZ_network_connections.py explode and it will expand the module into a folder. Enter the folder and then folder/ansible/module_utils Now we can see all the necessary dependencies - like module_utils/ - in this folder. The code {% highlight python %} with mock.patch.object( sys, \u0026ldquo;path\u0026rdquo;, [parentdir, os.path.join(parentdir, \u0026ldquo;module_utils/network_lsr\u0026rdquo;)] + sys.path, ): with mock.patch.dict( \u0026ldquo;sys.modules\u0026rdquo;, {\u0026ldquo;ansible\u0026rdquo;: mock.Mock(), \u0026ldquo;ansible.module_utils\u0026rdquo;: import(\u0026ldquo;module_utils\u0026rdquo;)}, ): import library.network_connections as nc {% endhighlight %}\nChanging sys.path Thanks to the mock object library, patching the value of an attribute from the object we need (in this case, sys.path) is not a difficult task, using patch.object. This function can take up to three arguments:\nThe object to be patched, (sys) the attribute that we want to change, (path) and the object used to replace the current value of the attribute. The object to that will be used is a list consisting of the current sys.path but adding the main directory of the project and the module_utils/network_lsr folder. This last folder is the one that is usually imported through Ansible instead of locally, but since we need to execute the project directly from Python, we need a workaround.\nUsing mock modules Similarly to the previous description, now that we have network_lsr in the path we want to import it in a way that the module thinks it\u0026rsquo;s from the Ansible library. This time, we use mock.patch.dict to patch sys.modules. Ansible gets imported as a Mock object and ansible.module_utils as module_utils.\n(Note that we can import module_utils thanks to the path workaround we did before.)\nImporting the library Thanks to the previous mocking, everything is ready to import the Network Role. Once it is imported, we can already create a custom RunEnvironment for the testing and therefore running tests without the need of executing them from Ansible.\nConclusion Although this was a nice step forward, now I\u0026rsquo;m trying to make an ansible playbook that makes the test compatible with different distributions, which is a new challenge for me. I hope I can bring more news and details on how to achieve that after August! =)\n","permalink":"http://localhost:1313/posts/2020-08-27-gsoc-isolating-network-role/","title":"Isolating the Network Role: How to mock the Ansible runtime"},{"content":"On this post I want to show the current process of debugging for the network system role and the reasons to add Pytest as tool for the integration tests, which is my task during the summer!\nIntro to the Network Role Since Linux System Roles is executed with Ansible, it is nice to take a look on what Ansible is. According to their main page: \u0026ldquo;Ansible is an IT automation tool. It can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates.\u0026rdquo;\nAn Ansible Role is a framework that manages collections of tasks and variables independently. Each role has a particular functionality. This said, Linux System Roles are a collection of Ansible Roles that admin the configuration of common GNU/Linux subsystems. The aim of Linux System Roles is to give a consistent API to a Linux distribution and making it consistent across their releases. Therefore, the Network Role is a role capable of configuring the networks of the machines that we want to manage through Ansible.\nIntegration Testing on the Network Role My main objective in this period is to be able to improve the testing of the network role. Right now, the system used to make integration testing are ansible-playbooks. These playbooks are the standard way of executing the role, but they present some problems when being used to make these tests.\nCurrent debugging workflow So, how to proceed if the current integration tests end with errors? First of all, since there is not a totally reliable source on the output that tells the developer if the role had an unexpected error. Right now, the best way of knowing this is returning the exit code of the process with the command echo $?.\nIf the output if different than 0, it means that there is something you need to change on your code. To make further debugging, it is convenient to execute the tests with the command:\nTEST_DEBUG=1 TEST_SUBJECTS=CentOS-8-GenericCloud-8.1.1911-20200113.3.x86_64.qcow2 ansible-playbook -v -i /usr/share/ansible/inventory/standard-inventory-qcow2 playbooks/tests_ethtool_features.yml --skip-tags tests::cleanup -e network_provider=initscripts What does this command do? TEST_DEBUG=1 - Indicates not to remove the VM that is created for the testing. TEST_SUBJECTS=/path/to/virtual/machine - Indicates which VM will be built to test the role. ansible-playbook -v - The command that execute the playbooks with the flag verbose -i /path/to/inventory - The inventory flag points to a script that sets the configuration for the testing. This script enables the variables TEST_DEBUG and TEST_SUBJECTS. /path/to/test.yml --skip-tags test::cleanup - This flag indicates the playbook to not execute the playbook blocks that have \u0026ldquo;test::cleanup\u0026rdquo; as a tag. Adding it will make the changes stay on the VM. This way we can later enter the VM and see what went wrong. -e network_provider=initscripts - This selects the provider we want to use to make the network changes. It can be either initscripts or nm. Executing this command will perform the tests and also output the information we need to later use the VM again, which are:\nThe ssh command to enter the VM. With this we can enter the VM and check the logs of the provider we used, to get more information on the problems encountered through the execution of the playbook.\nThe Ansible Inventory that can be used in case we want to execute the tests again with the same VM.\nAn example is:\n[INFO ] standard-inventory-qcow2: ssh -p 3266 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i /tmp/inventory-clouduyfw03ub/identity root@127.0.0.3 [INFO ] standard-inventory-qcow2: export ANSIBLE_INVENTORY=/tmp/inventory- clouduyfw03ub/inventory Aiming for a better integration testing Although integration testing can be done this way, introducing a tool like Pytest can help reduce debugging time and complexity. If Pytest is added, then Ansible would be no longer needed for the testing, since Pytest can simulate the changes performed by the Ansible program. Some of the benefits of using it, among others, would be:\nPytest is a widely known tool, so using it for integration testing would make the project more accesible to new developers.\nThe use of different Pytest features like fixtures can easily reduce writing complexity of tests and expand the coverage of the tests at the same time.\nThe introduction time to the project has helped me realize why it is important to improve the testing of the roles. The following weeks will be a complete challenge to me, but I think that the outcome of it will be completely worth it, both for me and for the project. =)\n","permalink":"http://localhost:1313/posts/2020-06-10-debugging-the-network-system-role/","title":"Debugging the Network System Role"},{"content":"Nice to meet you! I\u0026rsquo;m a Software Engineer currently working at Red Hat Openstack. My current focus is developing networking infrastructure for the cloud - This includes Neutron, which is the Openstack virtual networking component, and also Openshift Operators, which we currently use for the control plane deployment of Openstack (ovn-operator, neutron-operator\u0026hellip;).\nI enjoy side quests tasks too, like team coordination, and not just technical ones! Working remotely can leave a bit of a sense of loneliness and I find them nice to balance those sad vibes.\nOn my free time I like doing some silly art (like the little bird you can see on the bottom-right of this page!), petting any animal that exists, playing games and, above all, spending quality time with family and friends.\nSocial Links Github Mastodon Launchpad ","permalink":"http://localhost:1313/about/","title":""},{"content":"","permalink":"http://localhost:1313/search/","title":""}]